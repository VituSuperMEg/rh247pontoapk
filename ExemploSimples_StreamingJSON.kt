package com.ml.shubham0204.facenet_android.examples

import android.content.Context
import android.util.JsonReader
import android.util.JsonToken
import android.util.Log
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import java.io.*
import java.util.zip.GZIPInputStream

/**
 * ğŸš€ EXEMPLO SIMPLES: Como processar JSON gigante sem OutOfMemoryError
 *
 * âœ… PROBLEMA RESOLVIDO:
 * - OutOfMemoryError ao carregar JSON de 335MB
 * - Android limita memÃ³ria em ~256-268MB
 *
 * âœ… SOLUÃ‡ÃƒO:
 * - JsonReader (Gson Streaming API) - processa token por token
 * - Nunca carrega arquivo inteiro na memÃ³ria
 * - Processa em lotes de 500 registros
 * - Usa apenas ~10-20MB de RAM
 *
 * ğŸ“Š ESTRUTURA JSON ESPERADA:
 * {
 *   "timestamp": 1234567890,
 *   "version": "1.0",
 *   "data": {
 *     "pessoas": [
 *       {"id": 1, "nome": "JoÃ£o Silva", "idade": 30},
 *       {"id": 2, "nome": "Maria Santos", "idade": 25},
 *       ...
 *     ]
 *   }
 * }
 */
class ExemploStreamingJSON(private val context: Context) {

    companion object {
        private const val TAG = "ExemploStreamingJSON"
        private const val BATCH_SIZE = 500 // Salvar a cada 500 registros
    }

    /**
     * ğŸ¯ MÃ‰TODO PRINCIPAL: Restaura backup JSON grande
     *
     * @param arquivoJSON Arquivo JSON ou JSON.GZ
     */
    suspend fun restoreLargeJsonBackup(arquivoJSON: File) {
        withContext(Dispatchers.IO) {
            try {
                Log.d(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                Log.d(TAG, "ğŸš€ Iniciando processamento de JSON GIGANTE")
                Log.d(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                Log.d(TAG, "ğŸ“„ Arquivo: ${arquivoJSON.name}")
                Log.d(TAG, "ğŸ“Š Tamanho: ${arquivoJSON.length() / 1024 / 1024}MB")

                val startTime = System.currentTimeMillis()
                var totalProcessado = 0

                // 1ï¸âƒ£ CRIAR INPUT STREAM (detecta GZIP automaticamente)
                val inputStream = criarInputStream(arquivoJSON)

                // 2ï¸âƒ£ CRIAR JSONREADER COM BUFFER GRANDE
                inputStream.use { stream ->
                    InputStreamReader(stream, Charsets.UTF_8).use { reader ->
                        BufferedReader(reader, 64 * 1024).use { bufferedReader ->
                            JsonReader(bufferedReader).use { jsonReader ->

                                // Configurar modo leniente (aceita JSON nÃ£o 100% vÃ¡lido)
                                jsonReader.isLenient = true

                                // 3ï¸âƒ£ COMEÃ‡AR A LER JSON
                                jsonReader.beginObject() // {

                                while (jsonReader.hasNext()) {
                                    when (jsonReader.nextName()) {
                                        "timestamp" -> {
                                            val timestamp = jsonReader.nextLong()
                                            Log.d(TAG, "â° Timestamp: $timestamp")
                                        }
                                        "version" -> {
                                            val version = jsonReader.nextString()
                                            Log.d(TAG, "ğŸ“Œ VersÃ£o: $version")
                                        }
                                        "data" -> {
                                            // 4ï¸âƒ£ PROCESSAR SEÃ‡ÃƒO "data"
                                            jsonReader.beginObject() // data: {

                                            while (jsonReader.hasNext()) {
                                                when (jsonReader.nextName()) {
                                                    "pessoas" -> {
                                                        Log.d(TAG, "ğŸ‘¥ Processando PESSOAS...")
                                                        val count = processPessoas(jsonReader)
                                                        totalProcessado += count
                                                        Log.d(TAG, "âœ… $count pessoas processadas")
                                                    }
                                                    else -> jsonReader.skipValue()
                                                }
                                            }

                                            jsonReader.endObject() // }
                                        }
                                        else -> jsonReader.skipValue()
                                    }
                                }

                                jsonReader.endObject() // }
                            }
                        }
                    }
                }

                val totalTime = (System.currentTimeMillis() - startTime) / 1000.0
                Log.d(TAG, "")
                Log.d(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                Log.d(TAG, "âœ… PROCESSAMENTO CONCLUÃDO COM SUCESSO!")
                Log.d(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                Log.d(TAG, "ğŸ¯ Total: $totalProcessado registros")
                Log.d(TAG, "â±ï¸  Tempo: %.2f segundos".format(totalTime))
                Log.d(TAG, "ğŸš€ Taxa: %.0f registros/seg".format(totalProcessado / totalTime))
                logMemoria()
                Log.d(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

            } catch (e: OutOfMemoryError) {
                Log.e(TAG, "âŒ ERRO DE MEMÃ“RIA!", e)
                Log.e(TAG, "ğŸ’¡ Reduza o BATCH_SIZE de 500 para 250")
            } catch (e: Exception) {
                Log.e(TAG, "âŒ Erro ao processar JSON", e)
            }
        }
    }

    /**
     * ğŸ‘¥ Processa array de pessoas em lotes
     */
    private fun processPessoas(jsonReader: JsonReader): Int {
        jsonReader.beginArray() // [

        val batch = mutableListOf<Pessoa>()
        var count = 0
        var lastLogTime = System.currentTimeMillis()

        while (jsonReader.hasNext()) {
            // â­ PARSEAR CADA PESSOA INDIVIDUALMENTE
            val pessoa = parsePessoa(jsonReader)
            batch.add(pessoa)
            count++

            // Salvar lote quando atingir limite
            if (batch.size >= BATCH_SIZE) {
                salvarPessoasNoBanco(batch)
                batch.clear()

                // Log de progresso a cada 5 segundos
                val now = System.currentTimeMillis()
                if (now - lastLogTime >= 5000) {
                    Log.d(TAG, "   ğŸ“Š Processados: $count pessoas...")
                    logMemoria()
                    lastLogTime = now
                }

                // Liberar memÃ³ria
                System.gc()
            }
        }

        // Salvar resto
        if (batch.isNotEmpty()) {
            salvarPessoasNoBanco(batch)
            batch.clear()
        }

        jsonReader.endArray() // ]
        return count
    }

    /**
     * ğŸ“ Parseia uma pessoa individual
     */
    private fun parsePessoa(jsonReader: JsonReader): Pessoa {
        jsonReader.beginObject() // {

        var id = 0
        var nome = ""
        var idade = 0

        while (jsonReader.hasNext()) {
            when (jsonReader.nextName()) {
                "id" -> id = safeNextInt(jsonReader)
                "nome" -> nome = safeNextString(jsonReader)
                "idade" -> idade = safeNextInt(jsonReader)
                else -> jsonReader.skipValue() // Ignorar campos desconhecidos
            }
        }

        jsonReader.endObject() // }

        return Pessoa(id, nome, idade)
    }

    /**
     * ğŸ’¾ Salva lote de pessoas no banco (SQLite, Room, ObjectBox, etc)
     */
    private fun salvarPessoasNoBanco(pessoas: List<Pessoa>) {
        // ğŸ¯ AQUI VOCÃŠ SALVA NO SEU BANCO DE DADOS
        //
        // Exemplos:
        //
        // Room:
        // pessoaDao.insertAll(pessoas)
        //
        // ObjectBox:
        // val box = objectBoxStore.boxFor(Pessoa::class.java)
        // box.put(pessoas)
        //
        // SQLite direto:
        // db.beginTransaction()
        // pessoas.forEach { db.insert("pessoas", null, it.toContentValues()) }
        // db.setTransactionSuccessful()
        // db.endTransaction()

        Log.d(TAG, "ğŸ’¾ Salvando lote de ${pessoas.size} pessoas...")
    }

    /**
     * ğŸ—œï¸ Cria InputStream (com suporte a GZIP)
     */
    private fun criarInputStream(arquivo: File): InputStream {
        val isGzip = arquivo.name.endsWith(".gz", ignoreCase = true)

        val fis = FileInputStream(arquivo)
        val bis = BufferedInputStream(fis, 128 * 1024) // Buffer de 128KB

        return if (isGzip) {
            Log.d(TAG, "ğŸ—œï¸  Descomprimindo GZIP em tempo real...")
            GZIPInputStream(bis, 128 * 1024)
        } else {
            bis
        }
    }

    // ============================================
    // ğŸ›¡ï¸ SAFE PARSERS (Tratamento de nulls/erros)
    // ============================================

    private fun safeNextInt(jsonReader: JsonReader): Int {
        return try {
            if (jsonReader.peek() == JsonToken.NULL) {
                jsonReader.nextNull()
                0
            } else {
                jsonReader.nextInt()
            }
        } catch (e: Exception) {
            try {
                jsonReader.nextString().toIntOrNull() ?: 0
            } catch (e2: Exception) {
                0
            }
        }
    }

    private fun safeNextString(jsonReader: JsonReader): String {
        return try {
            if (jsonReader.peek() == JsonToken.NULL) {
                jsonReader.nextNull()
                ""
            } else {
                jsonReader.nextString()
            }
        } catch (e: Exception) {
            ""
        }
    }

    /**
     * ğŸ’¾ Log de memÃ³ria
     */
    private fun logMemoria() {
        val runtime = Runtime.getRuntime()
        val usedMB = (runtime.totalMemory() - runtime.freeMemory()) / 1024 / 1024
        val maxMB = runtime.maxMemory() / 1024 / 1024
        val percent = (usedMB * 100.0 / maxMB)

        Log.d(TAG, "   ğŸ’¾ MemÃ³ria: ${usedMB}MB / ${maxMB}MB (%.1f%%)".format(percent))
    }
}

/**
 * ğŸ“¦ Classe de dados simples
 */
data class Pessoa(
    val id: Int,
    val nome: String,
    val idade: Int
)

// ============================================
// ğŸ¯ COMO USAR:
// ============================================
//
// // No seu ViewModel ou Activity:
// viewModelScope.launch {
//     val exemplo = ExemploStreamingJSON(context)
//
//     // Processar JSON normal
//     val arquivo = File("/storage/emulated/0/Download/backup_335mb.json")
//     exemplo.restoreLargeJsonBackup(arquivo)
//
//     // Processar JSON comprimido (GZIP)
//     val arquivoGZ = File("/storage/emulated/0/Download/backup_335mb.json.gz")
//     exemplo.restoreLargeJsonBackup(arquivoGZ) // Descomprime automaticamente
// }
//
// ============================================
// ğŸ“Š LOGS ESPERADOS:
// ============================================
//
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// ğŸš€ Iniciando processamento de JSON GIGANTE
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// ğŸ“„ Arquivo: backup_335mb.json
// ğŸ“Š Tamanho: 335MB
// â° Timestamp: 1234567890
// ğŸ“Œ VersÃ£o: 1.0
// ğŸ‘¥ Processando PESSOAS...
//    ğŸ“Š Processados: 5000 pessoas...
//    ğŸ’¾ MemÃ³ria: 18MB / 256MB (7.0%)
//    ğŸ“Š Processados: 10000 pessoas...
//    ğŸ’¾ MemÃ³ria: 20MB / 256MB (7.8%)
// âœ… 50000 pessoas processadas
//
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// âœ… PROCESSAMENTO CONCLUÃDO COM SUCESSO!
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// ğŸ¯ Total: 50000 registros
// â±ï¸  Tempo: 45.32 segundos
// ğŸš€ Taxa: 1103 registros/seg
//    ğŸ’¾ MemÃ³ria: 22MB / 256MB (8.6%)
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
//
// ============================================
// ğŸ¯ VANTAGENS:
// ============================================
//
// âœ… Processa arquivos de QUALQUER tamanho
// âœ… MemÃ³ria constante (~15-25MB)
// âœ… Logs detalhados a cada 5 segundos
// âœ… Suporte a GZIP automÃ¡tico
// âœ… Tratamento de erros robusto
// âœ… Nunca trava a UI (usa Dispatchers.IO)
// âœ… Performance: ~1000-1500 registros/segundo
//
// ============================================
// ğŸ”§ AJUSTES POSSÃVEIS:
// ============================================
//
// Se ainda der OutOfMemoryError:
// - Reduza BATCH_SIZE de 500 para 250 ou 100
//
// Para melhor performance:
// - Aumente BATCH_SIZE para 1000 ou 2000
// - Aumente buffer para 256KB
//
// ============================================
